@article{joshi2022cogmen,
  title={COGMEN: COntextualized GNN based multimodal emotion recognitioN},
  author={Joshi, Abhinav and Bhat, Ashwani and Jain, Ayush and Singh, Atin Vikram and Modi, Ashutosh},
  journal={arXiv preprint arXiv:2205.02455},
  year={2022}
}

@article{KUMAR2022104483,
title = {MEmoR: A Multimodal Emotion Recognition using affective biomarkers for smart prediction of emotional health for people analytics in smart industries},
journal = {Image and Vision Computing},
volume = {123},
pages = {104483},
year = {2022},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2022.104483},
url = {https://www.sciencedirect.com/science/article/pii/S0262885622001123},
author = {Akshi Kumar and Kapil Sharma and Aditi Sharma},
}

@inproceedings{karatay2022multi,
  title={A Multi-Modal Emotion Recognition System Based on CNN-Transformer Deep Learning Technique},
  author={Karatay, Busra and Bestepe, Deniz and Sailunaz, Kashfia and Ozyer, Tansel and Alhajj, Reda},
  booktitle={2022 7th International Conference on Data Science and Machine Learning Applications (CDMA)},
  pages={145--150},
  year={2022},
  organization={IEEE}
}

@article{vidal2023multimodal,
  title={Multimodal attention for lip synthesis using conditional generative adversarial networks},
  author={Vidal, Andrea and Busso, Carlos},
  journal={Speech Communication},
  pages={102959},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{luo2019gan,
  title={A GAN-based data augmentation method for multimodal emotion recognition},
  author={Luo, Yun and Zhu, Li-Zhen and Lu, Bao-Liang},
  booktitle={Advances in Neural Networks--ISNN 2019: 16th International Symposium on Neural Networks, ISNN 2019, Moscow, Russia, July 10--12, 2019, Proceedings, Part I 16},
  pages={141--150},
  year={2019},
  organization={Springer}
}

@article{padi2022multimodal,
  title={Multimodal emotion recognition using transfer learning from speaker recognition and bert-based models},
  author={Padi, Sarala and Sadjadi, Seyed Omid and Manocha, Dinesh and Sriram, Ram D},
  journal={arXiv preprint arXiv:2202.08974},
  year={2022}
}

@article{salama20213d,
  title={A 3D-convolutional neural network framework with ensemble learning techniques for multi-modal emotion recognition},
  author={Salama, Elham S and El-Khoribi, Reda A and Shoman, Mahmoud E and Shalaby, Mohamed A Wahby},
  journal={Egyptian Informatics Journal},
  volume={22},
  number={2},
  pages={167--176},
  year={2021},
  publisher={Elsevier}
}

@article{zhang2021multimodal,
  title={Multimodal emotion recognition using a hierarchical fusion convolutional neural network},
  author={Zhang, Yong and Cheng, Cheng and Zhang, Yidie},
  journal={IEEE access},
  volume={9},
  pages={7943--7951},
  year={2021},
  publisher={IEEE}
}

@article{huan2021video,
  title={Video multimodal emotion recognition based on Bi-GRU and attention fusion},
  author={Huan, Ruo-Hong and Shu, Jia and Bao, Sheng-Lin and Liang, Rong-Hua and Chen, Peng and Chi, Kai-Kai},
  journal={Multimedia Tools and Applications},
  volume={80},
  pages={8213--8240},
  year={2021},
  publisher={Springer}
}

@article{cimtay2020cross,
  title={Cross-subject multimodal emotion recognition based on hybrid fusion},
  author={Cimtay, Yucel and Ekmekcioglu, Erhan and Caglar-Ozhan, Seyma},
  journal={IEEE Access},
  volume={8},
  pages={168865--168878},
  year={2020},
  publisher={IEEE}
}

@article{liu2023multi,
  title={Multi-modal fusion network with complementarity and importance for emotion recognition},
  author={Liu, Shuai and Gao, Peng and Li, Yating and Fu, Weina and Ding, Weiping},
  journal={Information Sciences},
  volume={619},
  pages={679--694},
  year={2023},
  publisher={Elsevier}
}

@article{le2023multi,
  title={Multi-Label Multimodal Emotion Recognition With Transformer-Based Fusion and Emotion-Level Representation Learning},
  author={Le, Hoai-Duy and Lee, Guee-Sang and Kim, Soo-Hyung and Kim, Seungwon and Yang, Hyung-Jeong},
  journal={IEEE Access},
  volume={11},
  pages={14742--14751},
  year={2023},
  publisher={IEEE}
}

@article{kumar2022interpretable,
  title={Interpretable multimodal emotion recognition using hybrid fusion of speech and image data},
  author={Kumar, Puneet and Malik, Sarthak and Raman, Balasubramanian},
  journal={arXiv preprint arXiv:2208.11868},
  year={2022}
}
@article{sharafi2022novel,
  title={A novel spatio-temporal convolutional neural framework for multimodal emotion recognition},
  author={Sharafi, Masoumeh and Yazdchi, Mohammadreza and Rasti, Reza and Nasimi, Fahimeh},
  journal={Biomedical Signal Processing and Control},
  volume={78},
  pages={103970},
  year={2022},
  publisher={Elsevier}
}
@article{zhang2023multimodal,
  title={Multimodal emotion recognition based on audio and text by using hybrid attention networks},
  author={Zhang, Shiqing and Yang, Yijiao and Chen, Chen and Liu, Ruixin and Tao, Xin and Guo, Wenping and Xu, Yicheng and Zhao, Xiaoming},
  journal={Biomedical Signal Processing and Control},
  volume={85},
  pages={105052},
  year={2023},
  publisher={Elsevier}
}

@article{siriwardhana2020multimodal,
  title={Multimodal emotion recognition with transformer-based self supervised feature fusion},
  author={Siriwardhana, Shamane and Kaluarachchi, Tharindu and Billinghurst, Mark and Nanayakkara, Suranga},
  journal={IEEE Access},
  volume={8},
  pages={176274--176285},
  year={2020},
  publisher={IEEE}
}

@inproceedings{huang2020multimodal,
  title={Multimodal transformer fusion for continuous emotion recognition},
  author={Huang, Jian and Tao, Jianhua and Liu, Bin and Lian, Zheng and Niu, Mingyue},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={3507--3511},
  year={2020},
  organization={IEEE}
}

@inproceedings{makiuchi2021multimodal,
  title={Multimodal emotion recognition with high-level speech and text features},
  author={Makiuchi, Mariana Rodrigues and Uto, Kuniaki and Shinoda, Koichi},
  booktitle={2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={350--357},
  year={2021},
  organization={IEEE}
}

@inproceedings{ju2020transformer,
  title={Transformer-based label set generation for multi-modal multi-label emotion detection},
  author={Ju, Xincheng and Zhang, Dong and Li, Junhui and Zhou, Guodong},
  booktitle={Proceedings of the 28th ACM international conference on multimedia},
  pages={512--520},
  year={2020}
}

@article{lian2021ctnet,
  title={CTNet: Conversational transformer network for emotion recognition},
  author={Lian, Zheng and Liu, Bin and Tao, Jianhua},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={985--1000},
  year={2021},
  publisher={IEEE}
}

@article{ma2022data,
  title={Data augmentation for audio-visual emotion recognition with an efficient multimodal conditional GAN},
  author={Ma, Fei and Li, Yang and Ni, Shiguang and Huang, Shao-Lun and Zhang, Lin},
  journal={Applied Sciences},
  volume={12},
  number={1},
  pages={527},
  year={2022},
  publisher={MDPI}
}

@article{abdullah2021multimodal,
  title={Multimodal emotion recognition using deep learning},
  author={Abdullah, Sharmeen M Saleem Abdullah and Ameen, Siddeeq Y Ameen and Sadeeq, Mohammed AM and Zeebaree, Subhi},
  journal={Journal of Applied Science and Technology Trends},
  volume={2},
  number={02},
  pages={52--58},
  year={2021}
}

@inproceedings{liang2020semi,
  title={Semi-supervised multi-modal emotion recognition with cross-modal distribution matching},
  author={Liang, Jingjun and Li, Ruichen and Jin, Qin},
  booktitle={Proceedings of the 28th ACM international conference on multimedia},
  pages={2852--2861},
  year={2020}
}

@article{setyono2023data,
  title={Data augmentation and enhancement for multimodal speech emotion recognition},
  author={Setyono, Jonathan Christian and Zahra, Amalia},
  journal={Bulletin of Electrical Engineering and Informatics},
  volume={12},
  number={5},
  pages={3008--3015},
  year={2023}
}
@inproceedings{maji2023multimodal,
  title={Multimodal Emotion Recognition Based on Deep Temporal Features Using Cross-Modal Transformer and Self-Attention},
  author={Maji, Bubai and Swain, Monorama and Guha, Rajlakshmi and Routray, Aurobinda},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@article{jia2022multimodal,
  title={A multimodal emotion recognition model integrating speech, video and MoCAP},
  author={Jia, Ning and Zheng, Chunjun and Sun, Wei},
  journal={Multimedia Tools and Applications},
  volume={81},
  number={22},
  pages={32265--32286},
  year={2022},
  publisher={Springer}
}

@article{chowdary2022emotion,
  title={Emotion recognition from EEG signals using recurrent neural networks},
  author={Chowdary, M Kalpana and Anitha, J and Hemanth, D Jude},
  journal={Electronics},
  volume={11},
  number={15},
  pages={2387},
  year={2022},
  publisher={MDPI}
}
@inproceedings{priyadarshini2023emotion,
  title={Emotion Recognition based on fusion of multimodal physiological signals using LSTM and GRU},
  author={Priyadarshini, N and Aravinth, J},
  booktitle={2023 Third International Conference on Secure Cyber Computing and Communication (ICSCCC)},
  pages={1--6},
  year={2023},
  organization={IEEE}
}
@inproceedings{hina2022multimodal,
  title={Multimodal emotion recognition using deep learning architectures},
  author={Hina, Iram and Shaukat, Arslan and Akram, Muhammad Usman},
  booktitle={2022 2nd International Conference on Digital Futures and Transformative Technologies (ICoDT2)},
  pages={1--6},
  year={2022},
  organization={IEEE}
}

@Article{s19122730,
AUTHOR = {Jiang, Wei and Wang, Zheng and Jin, Jesse S. and Han, Xianfeng and Li, Chunguang},
TITLE = {Speech Emotion Recognition with Heterogeneous Feature Unification of Deep Neural Network},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {12},
ARTICLE-NUMBER = {2730},
URL = {https://www.mdpi.com/1424-8220/19/12/2730},
PubMedID = {31216650},
}

@article{pan2023multimodal,
  title={Multimodal emotion recognition based on facial expressions, speech, and EEG},
  author={Pan, Jiahui and Fang, Weijie and Zhang, Zhihang and Chen, Bingzhi and Zhang, Zheng and Wang, Shuihua},
  journal={IEEE Open Journal of Engineering in Medicine and Biology},
  year={2023},
  publisher={IEEE}
}

@article{tzirakis2017end,
  title={End-to-end multimodal emotion recognition using deep neural networks},
  author={Tzirakis, Panagiotis and Trigeorgis, George and Nicolaou, Mihalis A and Schuller, Bj{\"o}rn W and Zafeiriou, Stefanos},
  journal={IEEE Journal of selected topics in signal processing},
  volume={11},
  number={8},
  pages={1301--1309},
  year={2017},
  publisher={IEEE}
}

@article{huang2019multimodal,
  title={Multimodal emotion recognition based on ensemble convolutional neural network},
  author={Huang, Haiping and Hu, Zhenchao and Wang, Wenming and Wu, Min},
  journal={IEEE Access},
  volume={8},
  pages={3265--3271},
  year={2019},
  publisher={IEEE}
}

@inproceedings{gu2021multimodal,
  title={Multimodal Emotion Recognition in Deep Learning: A Survey},
  author={Gu, Xin and Shen, Yinghua and Xu, Jie},
  booktitle={2021 International Conference on Culture-oriented Science \& Technology (ICCST)},
  pages={77--82},
  year={2021},
  organization={IEEE}
}


@Article{s19122730,
AUTHOR = {Jiang, Wei and Wang, Zheng and Jin, Jesse S. and Han, Xianfeng and Li, Chunguang},
TITLE = {Speech Emotion Recognition with Heterogeneous Feature Unification of Deep Neural Network},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {12},
ARTICLE-NUMBER = {2730},
URL = {https://www.mdpi.com/1424-8220/19/12/2730},
PubMedID = {31216650},
ISSN = {1424-8220},
}

@article{di2023randomized,
  title={A randomized deep neural network for emotion recognition with landmarks detection},
  author={Di Luzio, Francesco and Rosato, Antonello and Panella, Massimo},
  journal={Biomedical Signal Processing and Control},
  volume={81},
  pages={104418},
  year={2023},
  publisher={Elsevier}
}

@article{das2023emotion,
  title={Emotion Detection Using Generative Adversarial Network},
  author={Das, Sima and Ghosh, Ahona},
  journal={Generative Adversarial Networks and Deep Learning},
  pages={165--182},
  year={2023},
  publisher={Chapman and Hall/CRC}
}

@inproceedings{dimlo2023innovative,
  title={Innovative Method for Face Emotion Recognition using Hybrid Deep Neural Networks},
  author={Dimlo, UM Fernandes and Bhanarkar, Parul and Jayalakshmi, V and Sekhar, Savanam Chandra and Rastogi, Ravi and others},
  booktitle={2023 7th International Conference on Trends in Electronics and Informatics (ICOEI)},
  pages={876--881},
  year={2023},
  organization={IEEE}
}

@article{article,
author = {Gu, Geonmo and Kim, Seong Tae and Kim, Kihyun and Baddar, Wissam and Ro, Yong},
year = {2017},
month = {11},
pages = {},
title = {Differential Generative Adversarial Networks: Synthesizing Non-linear Facial Variations with Limited Number of Training Data}
}

@Article{electronics11091328,
AUTHOR = {Maji, Bubai and Swain, Monorama and Mustaqeem},
TITLE = {Advanced Fusion-Based Speech Emotion Recognition System Using a Dual-Attention Mechanism with Conv-Caps and Bi-GRU Features},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {9},
ARTICLE-NUMBER = {1328},
URL = {https://www.mdpi.com/2079-9292/11/9/1328},
ISSN = {2079-9292},
}

@article{aldawsari2023optimizing,
  title={Optimizing 1D-CNN-Based Emotion Recognition Process through Channel and Feature Selection from EEG Signals},
  author={Aldawsari, Haya and Al-Ahmadi, Saad and Muhammad, Farah},
  journal={Diagnostics},
  volume={13},
  number={16},
  pages={2624},
  year={2023},
  publisher={MDPI}
}

@article{hasnul2023augmenting,
  title={Augmenting ECG data with multiple filters for a better emotion recognition system},
  author={Hasnul, Muhammad Anas and Ab. Aziz, Nor Azlina and Abd. Aziz, Azlan},
  journal={Arabian Journal for Science and Engineering},
  pages={1--22},
  year={2023},
  publisher={Springer}
}

@article{karnati2023understanding,
  title={Understanding deep learning techniques for recognition of human emotions using facial expressions: a comprehensive survey},
  author={Karnati, Mohan and Seal, Ayan and Bhattacharjee, Debotosh and Yazidi, Anis and Krejcar, Ondrej},
  journal={IEEE Transactions on Instrumentation and Measurement},
  year={2023},
  publisher={IEEE}
}

@incollection{nagarajan2023emotion,
  title={Emotion Recognition from Videos Using Transformer Models},
  author={Nagarajan, Prabhitha and Kuriakose, Gem Rose and Mahajan, Arpana Dipak and Karuppasamy, Selvakuberan and Lakshminarayanan, Subhashini},
  booktitle={Computational Vision and Bio-Inspired Computing: Proceedings of ICCVBIC 2022},
  pages={45--56},
  year={2023},
  publisher={Springer}
}

@article{gu2023domain,
  title={A Domain Generative Graph Network for EEG-Based Emotion Recognition},
  author={Gu, Yun and Zhong, Xinyue and Qu, Cheng and Liu, Chuanjun and Chen, Bin},
  journal={IEEE Journal of Biomedical and Health Informatics},
  year={2023},
  publisher={IEEE}
}

@article{shehada2023lightweight,
  title={A Lightweight Facial Emotion Recognition System Using Partial Transfer Learning for Visually Impaired People},
  author={Shehada, Dina and Turky, Ayad and Khan, Wasiq and Khan, Bilal and Hussain, Abir},
  journal={IEEE Access},
  volume={11},
  pages={36961--36969},
  year={2023},
  publisher={IEEE}
}

@article{vempati2023systematic,
  title={A Systematic Review on Automated Human Emotion Recognition using Electroencephalogram Signals and Artificial Intelligence},
  author={Vempati, Raveendrababu and Sharma, Lakhan Dev},
  journal={Results in Engineering},
  pages={101027},
  year={2023},
  publisher={Elsevier}
}

@article{bai2023sect,
  title={SECT: A method of shifted EEG channel Transformer for emotion recognition},
  author={Bai, Zhongli and Hou, Fazheng and Sun, Kaixuan and Wu, Qingzhou and Zhu, Mu and Mao, Zemin and Song, Yu and Gao, Qiang},
  journal={IEEE Journal of Biomedical and Health Informatics},
  year={2023},
  publisher={IEEE}
}

@article{hsu2023applying,
  title={Applying Segment-Level Attention on Bi-modal Transformer Encoder for Audio-Visual Emotion Recognition},
  author={Hsu, Jia-Hao and Wu, Chung-Hsien},
  journal={IEEE Transactions on Affective Computing},
  year={2023},
  publisher={IEEE}
}

@article{wu2023transformer,
  title={Transformer-based self-supervised multimodal representation learning for wearable emotion recognition},
  author={Wu, Yujin and Daoudi, Mohamed and Amad, Ali},
  journal={IEEE Transactions on Affective Computing},
  year={2023},
  publisher={IEEE}
}

@article{kumar2023emotion,
  title={Emotion recognition in Hindi text using multilingual BERT transformer},
  author={Kumar, Tapesh and Mahrishi, Mehul and Sharma, Girish},
  journal={Multimedia Tools and Applications},
  pages={1--22},
  year={2023},
  publisher={Springer}
}

@article{bacsarslan2023mbi,
  title={MBi-GRUMCONV: A novel Multi Bi-GRU and Multi CNN-Based deep learning model for social media sentiment analysis},
  author={Ba{\c{s}}arslan, Muhammet Sinan and Kayaalp, Fatih},
  journal={Journal of Cloud Computing},
  volume={12},
  number={1},
  pages={5},
  year={2023},
  publisher={Springer}
}

@article{han2023speech,
  title={Speech Emotion Recognition Based on Deep Residual Shrinkage Network},
  author={Han, Tian and Zhang, Zhu and Ren, Mingyuan and Dong, Changchun and Jiang, Xiaolin and Zhuang, Quansheng},
  journal={Electronics},
  volume={12},
  number={11},
  pages={2512},
  year={2023},
  publisher={MDPI}
}

@article{liang2023mmateric,
  title={MMATERIC: Multi-Task Learning and Multi-Fusion for AudioText Emotion Recognition in Conversation},
  author={Liang, Xingwei and Zou, You and Zhuang, Xinnan and Yang, Jie and Niu, Taiyu and Xu, Ruifeng},
  journal={Electronics},
  volume={12},
  number={7},
  pages={1534},
  year={2023},
  publisher={MDPI}
}


@Article{app9204397,
AUTHOR = {Almabdy, Soad and Elrefaei, Lamiaa},
TITLE = {Deep Convolutional Neural Network-Based Approaches for Face Recognition},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {20},
ARTICLE-NUMBER = {4397},
URL = {https://www.mdpi.com/2076-3417/9/20/4397},
ISSN = {2076-3417}
}

@inproceedings{hu2023multiscale,
  title={A Multiscale Dynamic Temporal Convolution Network For Continuous Dimensional Emotion Recognition},
  author={Hu, Min and Sun, Jialu and Wang, Xiaohua and An, Ning},
  booktitle={2023 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--9},
  year={2023},
  organization={IEEE}
}

@article{zheng2023two,
  title={Two Birds With One Stone: Knowledge-Embedded Temporal Convolutional Transformer for Depression Detection and Emotion Recognition},
  author={Zheng, Wenbo and Yan, Lan and Wang, Fei-Yue},
  journal={IEEE Transactions on Affective Computing},
  year={2023},
  publisher={IEEE}
}
@article{r1,
  title={Deep learning-based facial emotion recognition for human–computer interaction applications},
  author={M. Kalpana Chowdary and Tu N. Nguyen and D. Jude Hemanth},
  journal={Neural Computing and Applications},
  year={2021},
  pages={1-18},
  url={https://api.semanticscholar.org/CorpusID:234854956}
}
@article{r2,
  title={Deep-Emotion: Facial Expression Recognition Using Attentional Convolutional Network},
  author={Shervin Minaee and AmirAli Abdolrashidi},
  journal={Sensors (Basel, Switzerland)},
  year={2019},
  volume={21},
  url={https://api.semanticscholar.org/CorpusID:59599957}
}

@article{r3,
  title={A review on sentiment analysis and emotion detection from text},
  author={Pansy Nandwani and Rupali Verma},
  journal={Social Network Analysis and Mining},
  year={2021},
  volume={11},
  url={https://api.semanticscholar.org/CorpusID:237344217}
}

@article{r4,
  title={Perceptual audio features for emotion detection},
  author={Mehmet Cenk Sezgin and Bilge G{\"u}nsel and G{\"u}nes Karabulut-Kurt},
  journal={EURASIP Journal on Audio, Speech, and Music Processing},
  year={2012},
  volume={2012},
  pages={1-21},
  url={https://api.semanticscholar.org/CorpusID:16205701}
}

@article{r5,
  title={A first look into a Convolutional Neural Network for speech emotion detection},
  author={Dario Bertero and Pascale Fung},
  journal={2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2017},
  pages={5115-5119},
  url={https://api.semanticscholar.org/CorpusID:12656747}
}

@article{r6,
	title = {Emotion {Theory} and {Research}: {Highlights}, {Unanswered} {Questions}, and {Emerging} {Issues}},
	volume = {60},
	issn = {0066-4308},
	shorttitle = {Emotion {Theory} and {Research}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2723854/},
	doi = {10.1146/annurev.psych.60.110707.163539},
	urldate = {2023-08-21},
	journal = {Annual review of psychology},
	author = {Izard, Carroll E.},
	year = {2009},
	pmid = {18729725},
	pmcid = {PMC2723854},
	pages = {1--25},
}

@article{r7,
  title={Emotion detection from multilingual audio using deep analysis},
  author={Bhattacharya, Sudipta and Borah, Samarjeet and Mishra, Brojo Kishore and Mondal, Atreyee},
  journal={Multimedia Tools and Applications},
  volume={81},
  number={28},
  pages={41309--41338},
  year={2022},
  publisher={Springer}
}

@inproceedings{r8,
  title={A study of feature extraction techniques for sentiment analysis},
  author={Avinash, M and Sivasankar, E},
  booktitle={Emerging Technologies in Data Mining and Information Security: Proceedings of IEMIS 2018, Volume 3},
  pages={475--486},
  year={2019},
  organization={Springer}
}

@inproceedings{r9,
  title={Improved feature selection approach TFIDF in text mining},
  author={Jing, Li-Ping and Huang, Hou-Kuan and Shi, Hong-Bo},
  booktitle={Proceedings. International Conference on Machine Learning and Cybernetics},
  volume={2},
  pages={944--946},
  year={2002},
  organization={IEEE}
}

@inproceedings{r10,
  title={Tokenization as the initial phase in NLP},
  author={Webster, Jonathan J and Kit, Chunyu},
  booktitle={COLING 1992 volume 4: The 14th international conference on computational linguistics},
  year={1992}
}

@article{r11,
  title={word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method},
  author={Goldberg, Yoav and Levy, Omer},
  journal={arXiv preprint arXiv:1402.3722},
  year={2014}
}
@article{r12,
  title={An empirical evaluation of doc2vec with practical insights into document embedding generation},
  author={Lau, Jey Han and Baldwin, Timothy},
  journal={arXiv preprint arXiv:1607.05368},
  year={2016}
}

@book{r13,
  title={Handbook of mathematical functions with formulas, graphs, and mathematical tables},
  author={Abramowitz, Milton and Stegun, Irene A},
  volume={55},
  year={1968},
  publisher={US Government printing office}
}

@inproceedings{r14,
  title={Distributed representations of sentences and documents},
  author={Le, Quoc and Mikolov, Tomas},
  booktitle={International conference on machine learning},
  pages={1188--1196},
  year={2014},
  organization={PMLR}
}

@inproceedings{r15,
  title={Distributed representations of sentences and documents},
  author={Le, Quoc and Mikolov, Tomas},
  booktitle={International conference on machine learning},
  pages={1188--1196},
  year={2014},
  organization={PMLR}
}

@article{r16,
  title={Parallelizing word2vec in shared and distributed memory},
  author={Ji, Shihao and Satish, Nadathur and Li, Sheng and Dubey, Pradeep K},
  journal={IEEE Transactions on Parallel and Distributed Systems},
  volume={30},
  number={9},
  pages={2090--2100},
  year={2019},
  publisher={IEEE}
}

@article{r17,
  title={Introduction to digital speech processing},
  author={Rabiner, Lawrence R and Schafer, Ronald W and others},
  journal={Foundations and Trends{\textregistered} in Signal Processing},
  volume={1},
  number={1--2},
  pages={1--194},
  year={2007},
  publisher={Now Publishers, Inc.}
}

@article{r18,
  title={Linear prediction: A tutorial review},
  author={Makhoul, John},
  journal={Proceedings of the IEEE},
  volume={63},
  number={4},
  pages={561--580},
  year={1975},
  publisher={IEEE}
}

@article{r19,
  title={Perceptual linear predictive (PLP) analysis of speech},
  author={Hermansky, Hynek},
  journal={the Journal of the Acoustical Society of America},
  volume={87},
  number={4},
  pages={1738--1752},
  year={1990},
  publisher={Acoustical Society of America}
}

@article{r20,
  title={A theory for multiresolution signal decomposition: the wavelet representation},
  author={Mallat, Stephane G},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={11},
  number={7},
  pages={674--693},
  year={1989},
  publisher={Ieee}
}


